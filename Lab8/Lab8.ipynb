{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the network with 500 steps and all of the distortion included, resulted in an accuracy of 0.516 on the evaluation set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the network with 500 steps and with the random flip removed from preprocessing, resulted in an accuracy of 0.520 on the evaluation set. From this reading, it can beshown that it the network is learning more quickly without the random flip but not by much. The random flip is a good preprocessing step to include to allow for extra rebustness in classifying the image regardless of the orientation of the image. Flipping the image isn't a huge distortion since the image is still the same and the edges and color are still intact but it is necessary to deal with more orientations of the image in prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the network with 500 steps and with the random distortion removed from preprocessing, resulted in an accuracy of 0.533 on the evaluation set. This shows that the network is capable of learning the features of the classes much quicker due to the lack of distortion in contrast and random brightness. These distortion would therefore cause the qualties of the classes to be harder detect and if the model was trained for more epochs, it should end in a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding these preprocessing steps, the model is more capable of handling images that are not perfectly taken or formated so a much larger range of possible images can be correctly classified. Despite this, looking at the accuracy obtained with distortion and without, it is easy to see that the distorted image take more epochs to reach the accuracy of the non-preprocessed images. If we were to train the network for a much longer time, the distortion would turn out to be an advantage because the model would be more rebust and could handle a larger range of possible images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further preprocessing could include:\n",
    " - Adding blur to the images.\n",
    " - Rotating the image.\n",
    " - Normalizing the pixel values of the image.\n",
    " - Perform a full scale contrast stretch to the image.\n",
    " - Adding gaussian noise or salt and pepper noise to the image.\n",
    " - Performing an edge detection algorithm using gradients or other methods.\n",
    " \n",
    "The actual preprocessing I would do is have a combination of unprocessed images and preprocessed images with distortion. The actual preprocessing I would do is create a set of all the different preprocessing methods I mentioned above as well as using the preprocessing steps that were used before. Then I would combine all these preprocessed images into a large set and draw the batches from that. I would then train the network for many more epochs than I did before and due to range of different images, the final model will have less variance and be better at final prediction of the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 Group Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team: Stefan Bordovsky, Rachel Chen, Kyle Grier, Danny Sutanto\n",
    "\n",
    "Our idea: Generate ambient music through a selected mood e.g. happy, sad, tense, chill\n",
    "\n",
    "First we need to scrape the web for labeled ambient music. We plan to scrape YouTube to download small clips of music files of videos like “Happy Ambient Music for 10 hours” or “Endless Tense Ambient Background Music” for us to use in our training set.\n",
    "\n",
    "Then we will teach a neural net how to generate its own ambient music from noise vectors and input mood type, taking inspiration from projects like WaveNet.\n",
    "\n",
    "Through this project we hope to answer many interesting questions like\n",
    "What musical characteristics do certain moods imply?\n",
    "Key\n",
    "Chord progression\n",
    "Rhythm, etc\n",
    "What is the need/desire behind ambient music?\n",
    "Why are people listening to these tracks? Others are uploading their music for a reason.\n",
    "Does our generated music have any semblance to what’s on YouTube?\n",
    "\n",
    "Preliminary Scraping: https://github.com/sbordov/EE379K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
