{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align:center\">EE 379K: Lab Five</p>\n",
    "# <p style=\"text-align:center\">Kyle Grier and Stefan Bordovsky</p>\n",
    "#### <p style=\"text-align:center\">Due: Monday, 10/09 3:00pm</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:40px\">\n",
    "    <b>Problem 3:</b> Problem 5 from Chapter 5 Estimating the test error of logistic regression using a\n",
    "validation set.\n",
    "<br>\n",
    "<div style=\"padding-left:60px\">5. In Chapter 4, we used logistic regression to predict the probability of default using income and balance on the Default data set. We will now estimate the test error of this logistic regression model using the validation set approach. Do not forget to set a random seed before beginning your analysis.</div>\n",
    "<div style=\"padding-left:80px\">(a) Fit a logistic regression model that uses income and balance to predict default.</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>defaulted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 default student      balance        income  defaulted\n",
       "0           1      No      No   729.526495  44361.625074          0\n",
       "1           2      No     Yes   817.180407  12106.134700          0\n",
       "2           3      No      No  1073.549164  31767.138947          0\n",
       "3           4      No      No   529.250605  35704.493935          0\n",
       "4           5      No      No   785.655883  38463.495879          0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random as rand\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "default_data = pd.read_csv('./default.csv')\n",
    "income_as_str = default_data.iloc[:, 4].values\n",
    "income = map(float, income_as_str)\n",
    "balance_as_str = default_data.iloc[:, 3].values\n",
    "balance = map(float, balance_as_str)\n",
    "\n",
    "default_data['defaulted'] = default_data['default'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "default_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9664\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>[-1.94173062729e-06]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>balance</td>\n",
       "      <td>[0.000407575689016]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>income</td>\n",
       "      <td>[-0.000125881139749]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                     1\n",
       "0  Intercept  [-1.94173062729e-06]\n",
       "1    balance   [0.000407575689016]\n",
       "2     income  [-0.000125881139749]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Referencing http://nbviewer.jupyter.org/gist/justmarkham/6d5c061ca5aee67c4316471f8c2ae976\n",
    "# create dataframes with an intercept column and columns for balance and income with a label column for dummy default variable.\n",
    "y, X = dmatrices('defaulted ~ balance + income',\n",
    "                  default_data, return_type=\"dataframe\")\n",
    "\n",
    "# Flatten y into a 1-D array by removing indices and leaving defaulted values.\n",
    "y = np.ravel(y)\n",
    "\n",
    "# Instantiate logistic regression.\n",
    "model = LogisticRegression()\n",
    "# Fit logistic regression using x, y.\n",
    "model = model.fit(X, y)\n",
    "\n",
    "# Accuracy on training set:\n",
    "print model.score(X, y)\n",
    "\n",
    "# y mean = percentage of people who defaulted.\n",
    "y.mean()\n",
    "\n",
    "# Coefficients computed by logistic regression:\n",
    "pd.DataFrame(zip(X.columns, np.transpose(model.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <div style=\"padding-left:80px\">\n",
    "        (b) Using the validation set approach, estimate the test error of this model. In order to do this, you must perform the following steps:\n",
    "    </div>\n",
    "    <div style=\"padding-left:100px\">\n",
    "        i. Split the sample set into a training set and a validation set.\n",
    "    </div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Still referencing http://nbviewer.jupyter.org/gist/justmarkham/6d5c061ca5aee67c4316471f8c2ae976\n",
    "# evaluate the model by splitting into train and test sets\n",
    "X_training, X_validation, y_training, y_validation = train_test_split(X, y, test_size=0.3, random_state= rand.randint(0, 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:100px\">\n",
    "    ii. Fit a multiple logistic regression model using only the training observations.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_model = LogisticRegression()\n",
    "training_model.fit(X_training, y_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:100px\">\n",
    "    iii. Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of default for that individual, and classifying the individual to the default category if the posterior probability is greater than 0.5.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict default status for the validation set.\n",
    "predicted = training_model.predict(X_validation)\n",
    "\n",
    "# Generate posterior probabilities of default.\n",
    "posterior_prob = training_model.predict_proba(X_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:100px\">\n",
    "    iv. Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0313333333333\n"
     ]
    }
   ],
   "source": [
    "# Validation set error = 1 - Validation set accuracy.\n",
    "validation_set_error = 1 - metrics.accuracy_score(y_validation, predicted)\n",
    "print(validation_set_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:80px\">\n",
    "    (c) Repeat the process in (b) three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set error for split 0: 0.0313333333333\n",
      "Validation set error for split 1: 0.0375\n",
      "Validation set error for split 2: 0.0335555555556\n"
     ]
    }
   ],
   "source": [
    "X_training_sets = {}\n",
    "X_validation_sets = {}\n",
    "y_training_sets = {}\n",
    "y_validation_sets = {}\n",
    "training_model_sets = {}\n",
    "predictions = {}\n",
    "posterior_probs = {}\n",
    "validation_set_errors = {}\n",
    "\n",
    "for i in range(3):\n",
    "    X_training_sets[i], X_validation_sets[i], y_training_sets[i], y_validation_sets[i] = train_test_split(X, y, test_size=0.30 * (1 + i), random_state=rand.randint(0, 10000))\n",
    "    training_model_sets[i] = LogisticRegression()\n",
    "    training_model_sets[i].fit(X_training_sets[i], y_training_sets[i])\n",
    "    \n",
    "    # Predict default status for the validation set.\n",
    "    predictions[i] = training_model_sets[i].predict(X_validation_sets[i])\n",
    "\n",
    "    # Generate posterior probabilities of default.\n",
    "    posterior_probs[i] = training_model_sets[i].predict_proba(X_validation_sets[i])\n",
    "    \n",
    "    # Validation set error = 1 - Validation set accuracy.\n",
    "    validation_set_errors[i] = 1 - metrics.accuracy_score(y_validation_sets[i], predictions[i])\n",
    "    print(\"Validation set error for split \" + str(i) + \": \" + str(validation_set_errors[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:100px\">\n",
    "    There is no apparent trend in validation set error dependent upon the ratio of test-set to training-set size upon running the above block of code.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:80px\">\n",
    "    (d) Now consider a logistic regression model that predicts the probability of default using income, balance, and a dummy variable for student. Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for student leads to a reduction in the test error rate.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set error for logistic regression with dummy student variable: 0.0326666666667\n"
     ]
    }
   ],
   "source": [
    "# Create a dummy variable for student.\n",
    "default_data['dummy_student'] = default_data['student'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Referencing http://nbviewer.jupyter.org/gist/justmarkham/6d5c061ca5aee67c4316471f8c2ae976\n",
    "# create dataframes with an intercept column and columns for balance, income, and dummy student variable\n",
    "y_DS, X_DS = dmatrices('defaulted ~ balance + income + dummy_student',\n",
    "                  default_data, return_type=\"dataframe\")\n",
    "\n",
    "# Flatten y into a 1-D array by removing indices and leaving defaulted values.\n",
    "y_DS = np.ravel(y_DS)\n",
    "\n",
    "# Instantiate logistic regression.\n",
    "model_DS = LogisticRegression()\n",
    "# Fit logistic regression using x, y.\n",
    "model_DS = model.fit(X_DS, y_DS)\n",
    "\n",
    "# Still referencing http://nbviewer.jupyter.org/gist/justmarkham/6d5c061ca5aee67c4316471f8c2ae976\n",
    "# Split model into train and test sets\n",
    "X_training_DS, X_validation_DS, y_training_DS, y_validation_DS = train_test_split(X_DS, y_DS, test_size=0.3, random_state= rand.randint(0, 10000))\n",
    "\n",
    "# Perform logistic regression on training sets.\n",
    "training_model_DS = LogisticRegression()\n",
    "training_model_DS.fit(X_training_DS, y_training_DS)\n",
    "\n",
    "# Predict default status for the validation set.\n",
    "predicted_DS = training_model_DS.predict(X_validation_DS)\n",
    "\n",
    "# Generate posterior probabilities of default.\n",
    "posterior_prob_DS = training_model_DS.predict_proba(X_validation_DS)\n",
    "\n",
    "# Validation set error = 1 - Validation set accuracy.\n",
    "validation_set_error_DS = 1 - metrics.accuracy_score(y_validation_DS, predicted_DS)\n",
    "print(\"Validation set error for logistic regression with dummy student variable: \" + str(validation_set_error_DS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:100px\">\n",
    "    Adding a dummy variable for student status yields no obvious change in logistic regression results.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:40px\">\n",
    "<b>Problem 4:</b> Problem 8 from Chapter 5.(Cross Validation). Use Google or any other means to find the Python counterpart to R's rnorm.)\n",
    "<br>\n",
    "<div style=\"padding-left:60px\">\n",
    "    8. We will now perform cross-validation on a simulated data set.\n",
    "</div>\n",
    "<div style=\"padding-left:80px\">\n",
    "    (a) Generate a simulated data set as follows:\n",
    "    <br>\n",
    "</div>\n",
    "<div style=\"padding-left:90px\"> \n",
    "> set.seed(1)\n",
    "<br>\n",
    "> x=rnorm(100)\n",
    "<br>\n",
    "> y=x-2*x^2+rnorm (100)\n",
    "<br>\n",
    "</div>\n",
    "<div style=\"padding-left:80px\">\n",
    "In this data set, what is n and what is p? Write out the model used to generate the data in equation form.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sbordovsky/anaconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "n = 100\n",
    "x = np.random.randn(n)\n",
    "y = x - (2 * np.power(x, 2)) + np.random.randn(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:100px\">\n",
    "    <i>(Referencing https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.normal.html)</i>\n",
    "    <br>\n",
    "    n for this data set is 100. p for the data set is 2.\n",
    "    <br>\n",
    "    The model for generating data used here is $y = x - 2x^2 + z$, where $x$ and $z$ are both arrays of size 100 generated from a gaussian distribution centered around mean 0 with standard deviation 1.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:80px\">\n",
    "    (b) Create a scatterplot of X against Y. Comment on what you find.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fb64c78ff90>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGrpJREFUeJzt3X+Q3HV9x/HXO8fJHNX2cIilObgGf4XiL66cFst0HCIS\nrLWcKP6o2jp2TOvUTnGYs0nTau3YMW2sjjNaNVNtZyqjYgkHDmqEgalTpqAXLxgipKVigIsd48Cp\nNSceybt/7G6yt3y/n/1+93b389n9Ph8zDNzu3t77luT7+n5+m7sLAIA862IXAABIG0EBAAgiKAAA\nQQQFACCIoAAABBEUAIAgggIAEERQAACCCAoAQNBpsQvohrPOOss3btwYuwwAGCj79u37obuvb/e6\noQiKjRs3an5+PnYZADBQzOxwkdfR9QQACCIoAABBBAUAIIigAAAEERQAgKChmPUEDJu5hUXt2ntI\nR5aWtWF8TLNbNmlmaiJ2WagoggJIzNzCorbvOaDlleOSpMWlZW3fc0CSCAtEQdcTkJhdew+dDImG\n5ZXj2rX3UKSKUHUEBZCYI0vLpR4Heo2gABKzYXys1ONArxEUQGJmt2zS2OjIqsfGRkc0u2VTpIpQ\ndQxmA4lpDFgz6wmpICiABM1MTRAMSEaSXU9mdq6Z3WFm3zGzg2b2Z7FrAoCqSrVF8YSka939W2b2\nNEn7zOxWd/9O7MKAQcdiPpSVZFC4+/clfb/+3z8xs/skTUgiKIA1YDEfOpFk11MzM9soaUrS3S2P\nbzWzeTObP3r0aIzSgIHDYj50IumgMLOnSrpB0jXu/uPm59x9t7tPu/v0+vVtT/IDIBbzoTPJBoWZ\njaoWEte5+57Y9QDDgMV86ESSQWFmJunTku5z9w/HrgfVMLewqEt23q7ztt2iS3berrmFxdgldR2L\n+dCJJAezJV0i6a2SDpjZ/vpjf+HuX45YE4bYWgd5B2UmEYv50Alz99g1rNn09LTPz8/HLgMD7JKd\nt2sxo59+YnxMd27bHPze1pCRanfpH7zqBVyAkTQz2+fu0+1el2qLAuirtQzyhmYSxQqKQWnhYDAQ\nFKi8uYVFrTPT8YzWdZFB3tRmErFWAt2W5GA20C+Ni2pWSBQd5O1kJlEvB85ZK4FuIyhQaVkXVUka\nMSs8xlB2JlEjnBaXluU6dcffrbBIrYWDwUdQoNLyLp4n3At308xMTeiDV71AE+NjMtUGwEMh0+s7\nftZKoNsYo0ClbRgfy5ztVPaiWmZb8F7f8c9u2ZQ5C4u1EugUQYFKy7uoXnr+el2y8/aezBrqVjjl\nKbpWgplRKIqgQKVlXVQvPX+9bti32LNZQ53c8Ze9qLdr4ZSdGUWoVBsL7oAWa1l8V1SZC2+nC/pC\nP6PM78iCwuHFgjugQ/2YNVRkTKNxoc+6oLdb0NeuxVDmd0xxQSH6i6AAWvR6DEFq36LIuotvFQqu\ndhf30O/YWlvW69r9/Obfgy6rwcf0WKBFr3dYnVtY1OwX71m1jmL2i/esWkeRt76jWSi48i7ii0vL\nJ7udrOW5xiB+6xqP1tcV+flS79eLoH9oUQAter3D6l/ffFArJ1aPDa6ccG3f8+2TP7PdyGG74Mpr\nCZh08nGvf+2qjU3MbtmUGVDNryv68yW6rIYJQQG06HV3ydLySubjyysncrt5mk0Eamoe12i9uLd+\nLT05JPJ+fuN1ZT4TVogPD4ICaDIIG+rlzbxqrb21xZAXAo3fMdTV1cmMr36M9aA/CAqgSbvukm60\nNs48Y1SPHctuVRT5Xml1y2GkvvPtSMYOuI2QuHPb5twpsY3fMU+n4zOsEB8eDGYDTULdJd0anH3f\nq5+n0ZG8IeKw//vZE/rLuQMn65B0MhyydsBt1C7VLtxlf2q7fatCyu6BhXQlu+DOzK6Q9FFJI5L+\nyd135r2WBXfohrmFRV17/T2ZF9yJendJ1h35+Nio9r/v8tI/q7ll8uhPH9fyyolC35vVcghp7jba\nuO2Wjr4Pw6nogrskWxRmNiLp45JeKekCSW8yswviVoVhVuRcirzWxtLySulWxczUhO7ctlkP7nyV\n7ty2WR+86oUaXVfsfr9MSLR29UzkjA9kTZWliwgNSQaFpJdIesDdv+vuP5f0eUlXRq4JiQodAlT0\ngKAi51KEBmHXukX4zNSEdl39olXdNNZZ75RGzHK7evLWiLz54km6iJAr1cHsCUkPN339iKTfaH6B\nmW2VtFWSJicn+1cZkhKapSSp8AymIudSzG7ZpGu+sD/zdd2Y8tm6rUeom2hsdCR3APpNv3GuPjDz\ngtyfIT15jYgk3XH/0U5Lx5BLNSjacvfdknZLtTGKyOUgknaHABVd8FVkKufM1ITe/6WDmTOW1plp\nbmHx5Pt2Y3ZU3pTWifoOt5+966HM72t3wW8NJHaSRTupBsWipHObvj6n/hgqrvki9Utjo7mL10J3\n+FnPtZvK2fi5jx1byVy4dty9o5ZMSKimUFdX2dZNmRXUg7DOBN2XalB8U9JzzOw81QLijZJ+L25J\niK31IpUXEtKplkDRBV+hbTuyFrJl6aQlExKq6d05XWB5v19IqjvJ0nJJR5JB4e5PmNm7JO1VbXrs\nZ9z9YOSyEFmRjfKk1S2BMgu+8rb+LvpzpfItmWZ5F8asmkJ7OZWdrVRmBXW/tuXIa7nMH35Ud9x/\nlPDos1RnPcndv+zuz3X3Z7n738auB/EVvRi99qKJkxfYbiz4KnMR3DA+lntHv84sd/ZV2cV8WbOX\nTNKbL54s/fuV2S0373fr9rYceS2X6+56iN1oI0g2KIBWRS9GN+xb1NzCYte6LspcBGe3bMq88Eq1\ncYy8C1y7QflWWSH4kTdcmDvbKaRMoOYF1KXnr5dUfDpyO3nh3NrtF/qM0D1Jdj0BWbIGd7MsrxzX\n+790UD9bOdHxoGtzyIyfMarRdfakrcFbnXnG6Kr3bnz/uoyV1K39+p106RQ5Ja+oou81MzWh+cOP\n6rq7Hjp50XbVwln1f3djoDt0YFIrdqPtPVoUGBgzUxN67UUThfYreuzYSqk79Gat3UCPHVuRrLZV\nh6n279a9msZGR/S+Vz9vVa2Nldcn2uzBJPWvS6cb7rj/aOad/XV3P9TxZ94qr+WSJcXPaNgQFBgo\nWRepMorcfWZ1A60cd/3C6afpwZ2v0v73Xa5dr3tR4bGPIiHQ61P1uim3Wyjnf8zi0rL+cu5AqS6p\nrO6wN188OTCf0bCh6wlJK3p+c7Ox0RGdftq6zOmzRe4+i3QDlen2KbLddpFT9VKZLlqmW6iheXFg\n0S6prM94+lefnsRnUDUEBZKVNUUyj9VXwTVvSdHpWQjdPnCn6NGqofBJaaFb0bGikKJrL7LCkR1t\n+4+gQLLKrF8YHxvVwnufvNV3J3efvThwZ60DzymdP50VfD99/IngAsgsRdaVpBKOVUdQIFllZrMs\nZey/1OnFuWgLoJ9SO3+63X5RRbRroaUUjlVHUCBZZfrCWzflKyq0Gjqli1Hq5083h+vi0nLmfljN\nirTQUgvHKmPWE5KVNRNodJ1lHiPa2JSvzAKvbh1t2g+DMCuqMSX4eztfpY+84cJVM5be0sF5F4M0\nZXjY0aJAskJnJ2QdWVq2W2KQujZS7A4L6UaL7NLz169a2CelF45VQVAgaXkXnLzdU8t0S+S9tuzU\nz7UoM+U1te6wXppbWNQN+xZXhYTp1D5e6C+CAgOpG332oR1YG+MdrRfyS89f37XdS5nVky+rtefi\nFL5YGKNAdJ1sJNeNPvvZLZsyt4Vw1S5UWWMYn+3i7qVlNwIcFN3YGJCB7LQQFIiq0wHlbmwhPjM1\nkTsz58jScqF1HGu5sA/jxTDr/+c1X9ivqb/5WqnAYCA7LXQ9IaqyA8rd3sYi71zqDeNjhS/YnV7Y\nU5/y2om8cH3s2EqpbrVeLHpE55JrUZjZLjO738y+bWY3mtl47JrQO2XuqnsxnTXUhVX0gt3phX0Q\npryWFQrNMq2vbh06he5IsUVxq6Tt9eNQ/07Sdkl/Hrkm9EiZu+peTGdtN+203WrjtVzYB23KaxHt\nFkmWaX1VaZZX6pILCnf/WtOXd0l6Xaxa0Htluhh61aefd0HKupB3c9ZT6GcPqnYbBg5yt1qVJRcU\nLd4u6Quxi0DvlLmrjtGnP2wX8l5rfFZ/ffPBJ20SOOjdalVmnnfaSC9/qNltks7OeGqHu99Uf80O\nSdOSrvKMIs1sq6StkjQ5OXnR4cOHe1gxUpC18dzY6Ah914nqxsSDVM7gGFZmts/dp9u+LkZQtGNm\nb5P0R5Je7u7H2r1+enra5+fne14X1oYLB8rgxqD3igZFcl1PZnaFpPdIelmRkMBg6GQVcmhnVwy/\nQdqLa9glNz1W0sckPU3SrWa238w+GbsgrF3ZVciDtLMremMYFyQOquSCwt2f7e7nuvuF9X/+OHZN\nWLvQBnxZ2zwM6/YWVbOW7TxYnZ2O5IICwyn0lzurtcDd5OBba6twGBckDiqCAqV1axO/Zq2tBe4m\nB99aW4Wszk5HcoPZSFveoPT84UeDC9Faj8rM0txaYK+fwdeNViGTF9JAUKCUvLvE5pPI8mY0Nf7S\nX7Lz9rYL52amJjR/+FF97u6HddxdI2Z67UW197pk5+1Mjx0A/Vgg2a3p0ky7DqPrCaXk3Q22rsYJ\ndTEU6XtunHDWOO70uLu+8I2HNftv9zATakD0eoyhWzPjmGHXHkGBUsrcDeaFSpG+56yWy8oJ18rx\n7HOyu6EbB+7glF6PMXRrZlzR96nynw+6nlBKu03fmoVCpV3fczfOvi6DY0l7o5djDN2aGVfkfar+\n54MWBUpp3CWeecZo8HVr7WIoe/b1WrFuY/B0a2Zckfep+p8PggKlzUxN6Iyn5DdGu9HFkNW/PbrO\nNDqy+pTrbvV5s25j8HRrDKTI+4QWjFahC4quJ3Qk7y+OSbpz2+Y1v3/e9uNZj3Wj6T+Mx5IOu24d\n/FTkfUIHMlWhCyrJ3WPLYvfY/sub4joxPtaVoOg3dipFSNafj2aD+ue+6O6xdD2hI8O2vQKrgBHS\n+PORZ9i7KOl6QkcaF9D3f+mgHjtWO8ns9NMG+76DVcAImZmayN1ZYNi7KAf7bzai+9nKiZP/vbS8\nwkIlDLXMSRYjpp8+/sRQr68gKNCxqk8ZRPW0dlGeecao5LWbpGFe1U1QoGNMKUUVzUxN6M5tm/Xg\nzlfpjKecppUTvdstIBUEBTrGVuCouqrcLCUbFGZ2rZm5mZ0VuxZkG7aZT0BZVblZSjIozOxcSZdL\neih2Lci31imlVd5kDcOhKjdLqU6P/Yik90i6KXYhCOt0SmnVN1nD4AidVdGt1eGpSy4ozOxKSYvu\nfo+ZtX09BlNoxtSw/SVDeooeVFTkhqYK62+iBIWZ3Sbp7Iyndkj6C9W6ndq9x1ZJWyVpcnKyq/Wh\n96oyCIj0lGnNckNTE2WMwt0vc/fnt/4j6buSzpN0j5l9T9I5kr5lZk8KFXff7e7T7j69fv36/v4C\nWLOqDAIiPWXW/3BDU5PUYLa7H3D3Z7j7RnffKOkRSb/u7v8buTR0WVUGAZGeMhd/bmhqkgoKVAeb\n8CGWMhd/bmhqkhvMblZvVWBIVWEQEOnJOs437+JflVlN7SQdFADQbWUv/tzQEBQAKoiLfzkEBdak\n6Hx0AIOLoEDHWF0NVAOzntAxzqMAqiE3KMzsy2a2sX+lYNCwGAmohlCL4p8lfc3MdpjZaL8KwuBg\nMRJQDbljFO7+RTP7iqS/kjRvZv8q6UTT8x/uQ31IWJn56AC6q58TSdoNZv9c0k8lnS7paWoKCoDF\nSEAc/Z5IkhsUZnaFpA9Lulm1/ZaOdf2nY+AxHx3ov37vahtqUeyQdLW7H+z6TwUAdKzfE0lyB7Pd\n/bcICQBIT78nkrCOAgAGTL93tWVlNgAMmH5PJCEoAGAA9XMiCV1PAIAgggIAEJRkUJjZn5rZ/WZ2\n0Mz+PnY9AFBlyY1RmNmlkq6U9CJ3f9zMnhG7JgCosuSCQtI7Je1098clyd1/ELkeAIgmhcPBUux6\neq6k3zKzu83s383sxVkvMrOtZjZvZvNHjx7tc4kA0HuNPZ0Wl5blOrWn09zCYl/riNKiMLPbJJ2d\n8dQO1Wp6uqSLJb1Y0vVm9kx39+YXuvtuSbslaXp62lvfCKekcEcCoLx+7+mUJ0pQuPtlec+Z2Tsl\n7akHwzfM7ISksyTRbOgAx5UCgyuVw8FS7Hqak3SpJJnZcyU9RdIPo1Y0wDiuFBhcqRwOlmJQfEbS\nM83sXkmfl/QHrd1OKC6VOxIA5fV7T6c8yc16cvefS3pL7DqGxYbxMS1mhALHlQLpS+VwsOSCAt3F\ncaXAYEvhcDCCYsilckcCYHARFBWQwh0JgMGV4mA2ACAhBAUAIIigAAAEERQAgCAGsyuGfZ8AlEVQ\nVAj7PgHoBF1PFcK+TwA6QVBUCPs+AegEQVEhqexECWCwEBQVkspOlAAGC4PZFcK+TwA6QVBUDPs+\nASiLricAQFByQWFmF5rZXWa238zmzewlsWsCgCpLLigk/b2k97v7hZLeW/8aABBJikHhkn6x/t+/\nJOlIxFoAoPJSHMy+RtJeM/uQakH2m5HrAYBKixIUZnabpLMzntoh6eWS3u3uN5jZ6yV9WtJlGe+x\nVdJWSZqcnOxhtQBQbebusWtYxcx+JGnc3d3MTNKP3P0XQ98zPT3t8/Pz/SkQAIaEme1z9+l2r0tx\njOKIpJfV/3uzpP+OWAsAVF6KYxTvkPRRMztN0s9U714CAMSRXFC4+39Iuih2HQCAmhS7ngAACSEo\nAABBBAUAIIigAAAEERQAgCCCAgAQRFAAAIIICgBAEEEBAAgiKAAAQQQFACCIoAAABBEUAIAgggIA\nEERQAACCCAoAQBBBAQAIihIUZna1mR00sxNmNt3y3HYze8DMDpnZlhj1AQBOiXUU6r2SrpL0qeYH\nzewCSW+U9DxJGyTdZmbPdffj/S8RACBFalG4+33ufijjqSslfd7dH3f3ByU9IOkl/a0OANAstTGK\nCUkPN339SP0xAEAkPet6MrPbJJ2d8dQOd7+pC++/VdJWSZqcnFzr23VkbmFRu/Ye0pGlZW0YH9Ps\nlk2amSLXAAyXngWFu1/WwbctSjq36etz6o9lvf9uSbslaXp62jv4WWsyt7Co7XsOaHmlNnyyuLSs\n7XsOSBJhAWCopNb1dLOkN5rZ6WZ2nqTnSPpG5Joy7dp76GRINCyvHNe119+juYXMbAOAgRRreuxr\nzOwRSS+VdIuZ7ZUkdz8o6XpJ35H0VUl/kuqMpyNLy5mPH3fX9j0HCAsAQyPWrKcb3f0cdz/d3X/Z\n3bc0Pfe37v4sd9/k7l+JUV8RG8bHcp9bXjmuXXuzJnUBwOBJretpYMxu2aSx0ZHc5/NaHAAwaAiK\nDs1MTeiDV71AI2aZz4daHAAwSAiKNZiZmtA/vP5FT2pZjI2OaHbLpkhVAUB3xdrCY2g0psKyngLA\nsCIoumBmaoJgADC06HoCAAQRFACAIIICABBEUAAAgggKAEAQQQEACCIoAABBBAUAIIigAAAEERQA\ngCCCAgAQRFAAAIJiHYV6tZkdNLMTZjbd9PgrzGyfmR2o/3tzjPoAAKfE2j32XklXSfpUy+M/lPRq\ndz9iZs+XtFcS27ICQERRgsLd75Mkazkdzt0Xmr48KGnMzE5398f7WB4AoEnKYxSvlfQtQgIA4upZ\ni8LMbpN0dsZTO9z9pjbf+zxJfyfp8sBrtkraKkmTk5NrqBQAENKzoHD3yzr5PjM7R9KNkn7f3f8n\n8P67Je2WpOnpae+oSABAW0l1PZnZuKRbJG1z9ztj1wMAiDc99jVm9oikl0q6xcz21p96l6RnS3qv\nme2v//OMGDUCAGpizXq6UbXupdbHPyDpA/2vCACQJ6muJwBAemItuEvC3MKidu09pCNLy9owPqbZ\nLZs0M8X6PgBoVtmgmFtY1PY9B7S8clyStLi0rO17DkgSYQEATSrb9bRr76GTIdGwvHJcu/YeilQR\nAKSpskFxZGm51OMAUFWVDYoN42OlHgeAqqpsUMxu2aSx0ZFVj42Njmh2y6ZIFQFAmio7mN0YsGbW\nEwCEVTYopFpYEAwAEFbZricAQDEEBQAgiKAAAAQRFACAIIICABBk7oN/OJyZHZV0OHYdTc6S9MPY\nRSSEz2M1Po9T+CxW6/fn8avuvr7di4YiKFJjZvPuPh27jlTweazG53EKn8VqqX4edD0BAIIICgBA\nEEHRG7tjF5AYPo/V+DxO4bNYLcnPgzEKAEAQLQoAQBBB0SNmtsvM7jezb5vZjWY2HrummMzsajM7\naGYnzCy5WR39YGZXmNkhM3vAzLbFricmM/uMmf3AzO6NXUsKzOxcM7vDzL5T/3vyZ7FrakZQ9M6t\nkp7v7i+U9F+StkeuJ7Z7JV0l6euxC4nBzEYkfVzSKyVdIOlNZnZB3Kqi+hdJV8QuIiFPSLrW3S+Q\ndLGkP0npzwdB0SPu/jV3f6L+5V2SzolZT2zufp+7V/lA8pdIesDdv+vuP5f0eUlXRq4pGnf/uqRH\nY9eRCnf/vrt/q/7fP5F0n6RkzkAgKPrj7ZK+ErsIRDUh6eGmrx9RQhcCpMPMNkqaknR33EpOqfTB\nRWtlZrdJOjvjqR3uflP9NTtUa1Ze18/aYijyeQDIZ2ZPlXSDpGvc/cex62kgKNbA3S8LPW9mb5P0\nO5Je7hWYh9zu86i4RUnnNn19Tv0xQJJkZqOqhcR17r4ndj3N6HrqETO7QtJ7JP2uux+LXQ+i+6ak\n55jZeWb2FElvlHRz5JqQCDMzSZ+WdJ+7fzh2Pa0Iit75mKSnSbrVzPab2SdjFxSTmb3GzB6R9FJJ\nt5jZ3tg19VN9YsO7JO1VbaDyenc/GLeqeMzsc5L+U9ImM3vEzP4wdk2RXSLprZI2168X+83st2MX\n1cDKbABAEC0KAEAQQQEACCIoAABBBAUAIIigAAAEERRAD9R3A33QzJ5e//rM+tcb41YGlEdQAD3g\n7g9L+oSknfWHdkra7e7fi1YU0CHWUQA9Ut+SYZ+kz0h6h6QL3X0lblVAeez1BPSIu6+Y2aykr0q6\nnJDAoKLrCeitV0r6vqTnxy4E6BRBAfSImV0o6RWqnVj2bjP7lcglAR0hKIAeqO8G+gnVzhV4SNIu\nSR+KWxXQGYIC6I13SHrI3W+tf/2Pkn7NzF4WsSagI8x6AgAE0aIAAAQRFACAIIICABBEUAAAgggK\nAEAQQQEACCIoAABBBAUAIOj/AcsDDX0m6rB3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb64b22e6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y, \"o\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:100px\">\n",
    "    The scatter plot of X vs Y resembles a parabola opening downwards, which reflects the $-2x^2$ term. It would resemble a parabolic arc exactly due to the x terms, but the z term adds noise to the function.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:80px\">\n",
    "    (c) Set a random seed, and then compute the LOOCV errors that result from fitting the following four models using least squares:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_validation import train_test_split, LeaveOneOut, KFold, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Set random seed.\n",
    "np.random.seed(7689)\n",
    "\n",
    "n = 100\n",
    "x_1 = np.random.randn(n)\n",
    "y_1 = x_1 - (2 * np.power(x_1, 2)) + np.random.randn(n)\n",
    "\n",
    "p_order = np.arange(1,5)\n",
    "\n",
    "# LeaveOneOut CV\n",
    "regr = skl_lm.LinearRegression()\n",
    "loo = LeaveOneOut(n)\n",
    "scores = list()\n",
    "\n",
    "# Find the Leave-One-Out Cross Validation error for polynomial model fits of order 1 to 4.\n",
    "for i in p_order:\n",
    "    poly = PolynomialFeatures(i)\n",
    "    X_poly = poly.fit_transform(x_1.reshape(-1, 1))\n",
    "    score = cross_val_score(regr, X_poly, y_1, cv=loo, scoring='neg_mean_squared_error').mean()\n",
    "    scores.append(score * -1)\n",
    "\n",
    "#df = pd.DataFrame({'$x':x, '$y':y})\n",
    "#df.columns = ['x', 'y']\n",
    "#df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:80px\">\n",
    "    <div style=\"padding-left:100px\">\n",
    "        i. $Y = β_0 + β_1X + \\varepsilon$\n",
    "    </div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOCV error for this order 1 polynomial model: 12.4657109716\n"
     ]
    }
   ],
   "source": [
    "print(\"LOOCV error for this order 1 polynomial model: \" + str(scores[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:100px\">\n",
    "    ii. $Y = β_0 + β_1X + β_2X^2 + \\varepsilon$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOCV error for this order 2 polynomial model: 1.02525780466\n"
     ]
    }
   ],
   "source": [
    "print(\"LOOCV error for this order 2 polynomial model: \" + str(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:100px\">\n",
    "   iii. $Y = β_0 + β_1X + β_2X^2 + β_3X^3 + \\varepsilon$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOCV error for this order 3 polynomial model: 1.03946378452\n"
     ]
    }
   ],
   "source": [
    "print(\"LOOCV error for this order 3 polynomial model: \" + str(scores[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:100px\">\n",
    "   iv. $Y = β_0 + β_1X + β_2X^2 + β_3X^3 + β_4X^4 + \\varepsilon$ \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOCV error for this order 4 polynomial model: 1.24138324237\n"
     ]
    }
   ],
   "source": [
    "print(\"LOOCV error for this order 4 polynomial model: \" + str(scores[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:80px\">\n",
    "    Note you may find it helpful to use the data.frame() function to create a single data set containing both X and Y .\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:80px\">\n",
    "    (d) Repeat (c) using another random seed, and report your results. Are your results the same as what you got in (c)? Why?\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOCV error for this order 1 polynomial model: 8.81132146332\n",
      "LOOCV error for this order 2 polynomial model: 0.901259442686\n",
      "LOOCV error for this order 3 polynomial model: 1.03347868477\n",
      "LOOCV error for this order 4 polynomial model: 1.17998727936\n"
     ]
    }
   ],
   "source": [
    "# Set random seed.\n",
    "np.random.seed(2008)\n",
    "\n",
    "n = 100\n",
    "x_2 = np.random.randn(n)\n",
    "y_2 = x_2 - (2 * np.power(x_2, 2)) + np.random.randn(n)\n",
    "\n",
    "p_order = np.arange(1,5)\n",
    "\n",
    "# LeaveOneOut CV\n",
    "regr = skl_lm.LinearRegression()\n",
    "loo = LeaveOneOut(n)\n",
    "scores = list()\n",
    "\n",
    "# Find the Leave-One-Out Cross Validation error for polynomial model fits of order 1 to 4.\n",
    "for i in p_order:\n",
    "    poly = PolynomialFeatures(i)\n",
    "    X_poly = poly.fit_transform(x_2.reshape(-1, 1))\n",
    "    score = cross_val_score(regr, X_poly, y_2, cv=loo, scoring='neg_mean_squared_error').mean()\n",
    "    scores.append(score * -1)\n",
    "    print(\"LOOCV error for this order \" + str(i) + \" polynomial model: \" + str(scores[i - 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:100px\">\n",
    "    The LOOCV errors for both random seeds are different. This is because we changed the values of the noise data from the underlying model, resulting in slight variation in the data values we used for cross validation.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:80px\">\n",
    "    (e) Which of the models in (c) had the smallest LOOCV error? Is this what you expected? Explain your answer\n",
    "</p>\n",
    "<p style=\"padding-left:100px\">\n",
    "    The order 2 polynomial model had the smallest LOOCV error. This was expected given that the underlying data was built off of an order 2 polynomial model.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:80px\">\n",
    "    (f) Comment on the statistical significance of the coefficient estimates that results from fitting each of the models in (c) using least squares. Do these results agree with the conclusions drawn based on the cross-validation results?\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
